{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Demo\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, count, rand, collect_list, explode, struct, count, lit\n",
    "from pyspark.sql.functions import udf, pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.range(0, 1000 * 1000).withColumn('id', (col('id') / 10000).cast('integer')).withColumn('v', rand())\n",
    "#df.cache()\n",
    "df.count()\n",
    "\n",
    "#df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf('double')\n",
    "def plus_one(v):\n",
    "    return v + 1\n",
    "\n",
    "%timeit df.withColumn('v', plus_one(df.v)).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"double\", PandasUDFType.SCALAR)\n",
    "def pandas_plus_one(v):\n",
    "    return v + 1\n",
    "\n",
    "%timeit df.withColumn('v', pandas_plus_one(df.v)).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "@udf('double')\n",
    "def cdf(v):\n",
    "    # stats.norm.cdf works on ints, lists, Pandas Series and NumPy arrays\n",
    "    return float(stats.norm.cdf(v))\n",
    "\n",
    "%timeit df.withColumn('cumulative_probability', cdf(df.v)).agg(count(col('cumulative_probability'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# returnType=PandasUDFType.SCALAR is implied\n",
    "@pandas_udf('double')\n",
    "def pandas_cdf(v):\n",
    "    return pd.Series(stats.norm.cdf(v))\n",
    "\n",
    "%timeit df.withColumn('cumulative_probability', pandas_cdf(df.v)).agg(count(col('cumulative_probability'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-------------------+------+\n",
      "| id|   v|               norm| fruit|\n",
      "+---+----+-------------------+------+\n",
      "|  1| 1.0|-0.7071067811865475| apple|\n",
      "|  1| 2.0| 0.7071067811865475|  pear|\n",
      "|  2| 3.0|-0.8320502943378437|orange|\n",
      "|  2| 5.0|-0.2773500981126146| grape|\n",
      "|  2|10.0| 1.1094003924504583| peach|\n",
      "+---+----+-------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grouped Map\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "df = spark.createDataFrame(\n",
    "    [(1, 1.0, \"apple\"),\n",
    "     (1, 2.0, \"pear\"),\n",
    "     (2, 3.0, \"orange\"),\n",
    "     (2, 5.0, \"grape\"),\n",
    "     (2, 10.0, \"peach\")],\n",
    "    (\"id\", \"v\", \"fruit\"))\n",
    "\n",
    "@pandas_udf(\"id long, v double, norm double, fruit string\", PandasUDFType.GROUPED_MAP)\n",
    "def normalize(pdf):\n",
    "    v = pdf.v\n",
    "    return pdf.assign(norm=(v - v.mean()) / v.std())\n",
    "\n",
    "df.groupby(\"id\").apply(normalize).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "970    0\n",
       "971    0\n",
       "972    0\n",
       "973    0\n",
       "974    0\n",
       "975    0\n",
       "976    0\n",
       "977    0\n",
       "978    0\n",
       "979    0\n",
       "980    0\n",
       "981    0\n",
       "982    0\n",
       "983    0\n",
       "984    0\n",
       "985    0\n",
       "986    0\n",
       "987    0\n",
       "988    0\n",
       "989    0\n",
       "990    0\n",
       "991    0\n",
       "992    0\n",
       "993    0\n",
       "994    0\n",
       "995    0\n",
       "996    0\n",
       "997    0\n",
       "998    0\n",
       "999    0\n",
       "Name: id, Length: 1000, dtype: int64\n",
       "Showing only the first 1000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import databricks.koalas as ks\n",
    "import numpy as np\n",
    "\n",
    "kdf = df.to_koalas()\n",
    "\n",
    "#kdf['norm'] = kdf.v.sub(kdf.v.mean()).div(kdf.v.std())\n",
    "\n",
    "#kdf.groupby(['id']).v.(1) #.sub(kdf.v.mean()).div(kdf.v.std())\n",
    "#kdf.groupby(['id', 'v']).min()\n",
    "\n",
    "def printer(s) -> np.int64:\n",
    "    return s*2\n",
    "\n",
    "kdf['id'].apply(printer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
